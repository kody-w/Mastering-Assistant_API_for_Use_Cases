# -*- coding: utf-8 -*-
"""üßô‚Äç‚ôÇÔ∏è OAI Assistants API üßô‚Äç‚ôÇÔ∏è

Automatically generated by Colaboratory.

Original file is located at:
    https://colab.research.google.com/drive/1dhFFpTrdW4F0j355LlBqGP6Dfzitk2JQ
"""

# Import statements
import openai
import instructor
from getpass import getpass
from openai import Client

# Create an OpenAI client
client = Client(api_key=getpass("Paste your openai api key: "))

import textwrap
import builtins

# Custom print function
def wprint(*args, width=70, **kwargs):
    """
    üñ®Ô∏è Custom print function that wraps text to a specified width.
    """
    wrapper = textwrap.TextWrapper(width=width)
    wrapped_args = [wrapper.fill(str(arg)) for arg in args]
    builtins.print(*wrapped_args, **kwargs)

# ASCII Art Divider
def print_divider():
    print("\n" + "=" * 70 + "\n")

# Get completion function
import time

def get_completion(message, agent, funcs, thread):
    """
    üîÑ Executes a thread based on a provided message and retrieves the completion result.
    """
    # Create new message in the thread
    message = client.beta.threads.messages.create(
        thread_id=thread.id,
        role="user",
        content=message
    )

    # Run this thread
    run = client.beta.threads.runs.create(
      thread_id=thread.id,
      assistant_id=agent.id,
    )

    while True:
      # Wait until run completes
      while run.status in ['queued', 'in_progress']:
        run = client.beta.threads.runs.retrieve(
          thread_id=thread.id,
          run_id=run.id
        )
        time.sleep(1)

      # Function execution
      if run.status == "requires_action":
        tool_calls = run.required_action.submit_tool_outputs.tool_calls
        tool_outputs = []
        for tool_call in tool_calls:
          wprint('\033[31m' + str(tool_call.function), '\033[0m')
          func = next(iter([func for func in funcs if func.__name__ == tool_call.function.name]))

          try:
            func = func(**eval(tool_call.function.arguments))
            output = func.run()
          except Exception as e:
            output = "Error: " + str(e)

          wprint(f"\033[33m{tool_call.function.name}: ", output, '\033[0m')
          tool_outputs.append({"tool_call_id": tool_call.id, "output": output})

        run = client.beta.threads.runs.submit_tool_outputs(
            thread_id=thread.id,
            run_id=run.id,
            tool_outputs=tool_outputs
        )
      elif run.status == "failed":
        print_divider()
        raise Exception("üö® Run Failed. Error: ", run.last_error)
      else:
        messages = client.beta.threads.messages.list(
          thread_id=thread.id
        )
        message = messages.data[0].content[0].text.value
        return message

# Code Assistant
from typing import List
from pydantic import Field
from instructor import OpenAISchema
import subprocess

class ExecutePyFile(OpenAISchema):
    """
    Run existing python file from local disc.
    """
    file_name: str = Field(
        ..., description="The path to the .py file to be executed."
    )

    def run(self):
      """
      Executes a Python script at the given file path and captures its output and errors.
      """
      try:
          result = subprocess.run(
              ['python3', self.file_name],
              text=True,
              capture_output=True,
              check=True
          )
          return result.stdout
      except subprocess.CalledProcessError as e:
          return f"An error occurred: {e.stderr}"

class File(OpenAISchema):
    """
    Python file with an appropriate name, containing code that can be saved and executed locally at a later time.
    """
    chain_of_thought: str = Field(...,
        description="Think step by step to determine the correct actions that are needed to be taken in order to complete the task.")
    file_name: str = Field(
        ..., description="The name of the file including the extension"
    )
    body: str = Field(..., description="Correct contents of a file")

    def run(self):
        with open(self.file_name, "w") as f:
            f.write(self.body)
        return "File written to " + self.file_name


code_assistant_funcs = [File, ExecutePyFile]

code_assistant = client.beta.assistants.create(
  name='Code Assistant Agent',
  instructions="""ü§ñ As a top-tier programming AI, you are adept at creating accurate Python scripts. 
  You will properly name files and craft precise Python code with the appropriate imports to fulfill the user's request. 
  Ensure to execute the necessary code before responding to the user.""",
  model="gpt-4-1106-preview",
  tools=[{"type": "function", "function": File.openai_schema},
         {"type": "function", "function": ExecutePyFile.openai_schema},]
)

# User Proxy
from enum import Enum
from pydantic import PrivateAttr
from typing import Literal

agents_and_threads = {
    "code_assistant": {
        "agent": code_assistant,
        "thread": None,
        "funcs": code_assistant_funcs
    }
}

class SendMessage(OpenAISchema):
    """
    Send messages to other specialized agents in this group chat.
    """
    recepient: Literal['code_assistant'] = Field(..., description="code_assistant is a world class programming AI capable of executing python code.")
    message: str = Field(...,
        description="Specify the task required for the recipient agent to complete. Focus instead on clarifying what the task entails, rather than providing detailed instructions.")

    def run(self):
      recepient = agents_and_threads[self.recepient]
      if not recepient["thread"]:
        recepient["thread"] = client.beta.threads.create()

      message = get_completion(message=self.message, **recepient)

      return message

user_proxy_tools = [SendMessage]

user_proxy = client.beta.assistants.create(
  name='User Proxy Agent',
  instructions="""üó£Ô∏è As a user proxy agent, your responsibility is to streamline the dialogue between the user and specialized agents within this group chat.
  Your duty is to articulate user requests accurately to the relevant agents and maintain ongoing communication with them to guarantee the user's task is carried out to completion.
  Please do not respond to the user until the task is complete, an error has been reported by the relevant agent, or you are certain of your response.""",
  model="gpt-4-1106-preview",
  tools=[
      {"type": "function", "function": SendMessage.openai_schema},
  ],
)

# Autogen Example Questions:
"""
1. What is today's date?
2. Compare the year-to-date gain for META and TESLA.
3. Plot a chart of their stock price change YTD and save to stock_price_ytd.png.
"""

# Main execution loop
thread = client.beta.threads.create()
while True:
  user_message = input("üí¨ User: ")
  message = get_completion(user_message, user_proxy, user_proxy_tools, thread)
  print_divider()
  wprint(f"ü§ñ {user_proxy.name}: ", message, '\033[0m')
